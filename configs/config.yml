# Mimir Main Configuration

# Timezone for date/time operations
timezone: Asia/Shanghai

# Notion integration settings
notion:
  database_id: ${NOTION_DATABASE_ID}  # From environment variable
  # Field names in Notion database (must match your database schema)
  field_names:
    title: "Title"  # English field name
    source_type: "Source Type"
    link: "Link"
    date: "Date"
    priority: "Priority"
    topics: "Topics"
    status: "Status"

# Content processing settings
processing:
  enable_llm: false  # Phase 1: false, Phase 2: optional (use llm.enabled instead)
  enable_keyword_classification: true  # Phase 1: use keyword-based classification
  deduplication:
    method: url  # url, semantic, both
  
  # Content cleaning processor
  cleaning:
    enabled: true
    remove_ads: true
    normalize_encoding: true
    max_summary_length: 500
  
  # Quality assessment processor
  quality:
    enabled: true
    min_quality_score: 0.3  # Entries below this score will be filtered
    source_whitelist: []  # Trusted source domains (e.g., ["arxiv.org", "github.com"])
    source_blacklist: []  # Untrusted source domains
    min_content_length: 50  # Minimum content length in characters
  
  # Semantic deduplication processor
  semantic_dedup:
    enabled: false  # Disabled by default (requires sentence-transformers)
    similarity_threshold: 0.85  # Similarity threshold for duplicates
    embedding_model: null  # Model name (e.g., "sentence-transformers/all-MiniLM-L6-v2")
    use_openai_embedding: false  # Use OpenAI embeddings instead
  
  # Information verification processor
  verification:
    enabled: true
    verify_source: true  # Verify source domain
    cross_verify: false  # Cross-verify with other sources
    fact_check_llm: false  # Use LLM for fact-checking (expensive)
    source_whitelist: []  # Trusted source domains
  
  # Knowledge extraction processor
  knowledge_extraction:
    enabled: true
    extract_entities: true  # Extract entities (people, organizations, technologies)
    extract_relations: true  # Extract relations between entities
    extract_key_points: true  # Extract key points
    use_llm: false  # Use LLM for extraction (optional)
  
  # Priority ranking processor
  ranking:
    enabled: true
    weights:
      quality: 0.4  # Weight for quality score
      relevance: 0.3  # Weight for relevance
      timeliness: 0.2  # Weight for timeliness
      source: 0.1  # Weight for source authority

# LLM settings (Phase 2)
llm:
  enabled: false  # Must be explicitly enabled
  provider: openai  # openai, anthropic, etc.
  model: gpt-4o-mini  # Model name
  base_url: null  # Optional: Custom API base URL (for OpenAI-compatible APIs, local models, or proxies)
  # Examples:
  # base_url: "https://api.openai.com/v1"  # Default OpenAI
  # base_url: "http://localhost:1234/v1"  # Local model server (e.g., Ollama, vLLM)
  # base_url: "https://api.example.com/v1"  # Custom proxy or compatible API
  daily_limit: 5.0  # USD per day
  monthly_budget: 50.0  # USD per month
  features:
    summarization: true  # Generate LLM summaries
    translation: true  # Translate content
    smart_categorization: true  # Use LLM for topic/priority classification
  translation:
    target_languages: ["zh", "en"]  # Optional translation targets

# Cache settings
cache:
  enabled: true
  path: ./data/cache
  ttl_days: 30

# Retry settings
retry:
  max_attempts: 3
  backoff_factor: 2

# DingTalk notification settings (Phase 3)
dingtalk:
  enabled: false  # Set to true to enable DingTalk notifications
  webhook_url: ${DINGTALK_WEBHOOK_URL}  # From environment variable
  secret: ${DINGTALK_SECRET}  # Optional: webhook secret for signature

